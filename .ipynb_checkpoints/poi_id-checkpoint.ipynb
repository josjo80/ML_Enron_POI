{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshuajohnson/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('kbest', SelectKBest(k=8, score_func=<function f_classif at 0x11677c758>)), ('GNB', GaussianNB())])\n",
      "\tAccuracy: 0.84143\tPrecision: 0.43963\tRecall: 0.40050\tF1: 0.41915\tF2: 0.40776\n",
      "\tTotal predictions: 14000\tTrue positives:  801\tFalse positives: 1021\tFalse negatives: 1199\tTrue negatives: 10979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import test_classifier, dump_classifier_and_data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "### Task 1: Select what features you'll use.\n",
    "### features_list is a list of strings, each of which is a feature name.\n",
    "### The first feature must be \"poi\".\n",
    "features_list = ['poi', 'salary', 'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', \n",
    "                  'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', \n",
    "                  'long_term_incentive', 'restricted_stock', 'director_fees', 'to_messages', \n",
    "                  'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi'] \n",
    "                 \n",
    "### Load the dictionary containing the dataset\n",
    "data_dict = pickle.load(open(\"final_project_dataset.pkl\", \"r\") )\n",
    "#print data_dict\n",
    "\n",
    "### Task 2: Remove outliers\n",
    "#Get labels and features\n",
    "df = pd.DataFrame.from_dict(data_dict, orient = 'index', dtype = float)\n",
    "df = pd.DataFrame(df, columns = features_list)\n",
    "\n",
    "'''\n",
    "print len(df[df['poi'] == 1.0])\n",
    "print len(df[df['poi'] == 0.0])\n",
    "'''\n",
    "#Identify any outliers by name\n",
    "#print data_dict.keys()\n",
    "##Found 2 names that do not appear to be people:\n",
    "##'TOTAL'\n",
    "##'THE TRAVEL AGENCY IN THE PARK'\n",
    "\n",
    "from outlier_cleaner_final2 import outlierCleaner\n",
    "cleaned_data = outlierCleaner( df )\n",
    "\n",
    "data_dict.pop(\"TOTAL\", 0)\n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK', 0)\n",
    "data_dict.pop(\"BECK SALLY W\", 0)\n",
    "data_dict.pop(\"KAMINSKI WINCENTY J\", 0)\n",
    "data_dict.pop(\"KEAN STEVEN J\", 0)\n",
    "data_dict.pop(\"LAVORATO JOHN J\", 0)\n",
    "data_dict.pop('BHATNAGAR SANJAY', 0)\n",
    "data_dict.pop('SHAPIRO RICHARD S', 0)\n",
    "\n",
    "\n",
    "### Task 3: Create new feature(s)\n",
    "from computefraction import computeFraction\n",
    "\n",
    "submit_dict = {}\n",
    "for name in data_dict:\n",
    "\n",
    "    data_point = data_dict[name]\n",
    "\n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    fraction_from_poi = computeFraction( from_poi_to_this_person, to_messages )\n",
    "    #print fraction_from_poi\n",
    "    data_point[\"fraction_from_poi\"] = fraction_from_poi\n",
    "\n",
    "\n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\n",
    "    #print fraction_to_poi\n",
    "    data_point[\"fraction_to_poi\"] = fraction_to_poi\n",
    "\n",
    "\n",
    "### Store to my_dataset for easy export below.\n",
    "my_dataset = data_dict\n",
    "\n",
    "### Extract features and labels from dataset for local testing\n",
    "features_list.append('fraction_from_poi')\n",
    "features_list.append('fraction_to_poi')\n",
    "data = featureFormat(data_dict, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "\n",
    "##Selecting best K features out of all\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "K = 8\n",
    "selector = SelectKBest(k=K)\n",
    "selector.fit(features, labels)\n",
    "#print selector.scores_\n",
    "\n",
    "#List comprehension of the selector scores and features\n",
    "fs = [[e, i] for e, i in zip(selector.scores_, features_list[1:])]\n",
    "\n",
    "fs = sorted(fs, key=lambda fs_list: fs_list[0], reverse = True)\n",
    "fs = fs[:K]\n",
    "features_list = [e[1] for e in fs]\n",
    "features_list = ['poi'] + features_list\n",
    "#print '***************'\n",
    "#print fs\n",
    "#print features_list\n",
    "\n",
    "#Re-create features, labels based on optimized features_list\n",
    "data = featureFormat(data_dict, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "\n",
    "#Assuming GaussianNB, below are the results for particular K's\n",
    "#K = 5, Precision: 0.47626\tRecall: 0.34100\n",
    "#K = 6, Precision: 0.47247\tRecall: 0.34750\n",
    "#K = 7, Precision: 0.48092\tRecall: 0.37800\n",
    "#K = 8, Precision: 0.48026\tRecall: 0.40750\n",
    "#K = 9, Precision: 0.47995\tRecall: 0.40700\n",
    "#K = 10, Precision: 0.44684\tRecall: 0.39300\n",
    "#K = 8 is optimum\n",
    "\n",
    "\n",
    "\n",
    "### Task 4: Try a varity of classifiers\n",
    "### Please name your classifier clf for easy export below.\n",
    "### Note that if you want to do PCA or other multi-stage operations,\n",
    "### you'll need to use Pipelines. For more info:\n",
    "### http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import ensemble\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "\n",
    "\n",
    "GNB = GaussianNB()\n",
    "parameters = {'kbest__k': [1,2,3,4,5,6,7,8]}\n",
    "Min_Max_scaler = MinMaxScaler()\n",
    "kbest = SelectKBest()\n",
    "pipeline = Pipeline(steps=[('scaler', Min_Max_scaler), ('kbest', kbest), ('GNB', GNB)])\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "#Results - Outliers = TOTAL, 'THE TRAVEL AGENCY IN THE PARK'\n",
    "#Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('kbest', SelectKBest(k=5, score_func=<function f_classif at 0x117403a28>)), ('GNB', GaussianNB())])\n",
    "#\tAccuracy: 0.85033\tPrecision: 0.42562\tRecall: 0.35050\tF1: 0.38443\tF2: 0.36333\n",
    "#\tTotal predictions: 15000\tTrue positives:  701\tFalse positives:  946\tFalse negatives: 1299\tTrue negatives: 12054\n",
    "\n",
    "#Results - Outliers = All\n",
    "#Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('kbest', SelectKBest(k=8, score_func=<function f_classif at 0x11677c758>)), ('GNB', GaussianNB())])\n",
    "#\tAccuracy: 0.84143\tPrecision: 0.43963\tRecall: 0.40050\tF1: 0.41915\tF2: 0.40776\n",
    "#\tTotal predictions: 14000\tTrue positives:  801\tFalse positives: 1021\tFalse negatives: 1199\tTrue negatives: 10979\n",
    "\n",
    "\n",
    "'''\n",
    "KNC = KNeighborsClassifier()\n",
    "parameters = {'KNC__n_neighbors' : [1, 5, 10],\n",
    "          'KNC__algorithm' : ('ball_tree', 'kd_tree'),\n",
    "          'KNC__leaf_size' : [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "          'KNC__p' : [1,2,3], 'kbest__k':range(1,9)}\n",
    "Min_Max_scaler = MinMaxScaler()\n",
    "kbest = SelectKBest()\n",
    "pipeline = Pipeline(steps=[('scaler', Min_Max_scaler), (\"kbest\", kbest), ('KNC', KNC)])\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "#Results - Outliers = All\n",
    "#Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('kbest', SelectKBest(k=3, score_func=<function f_classif at 0x116bff9b0>)), ('KNC', KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, metric='minkowski',\n",
    "#           metric_params=None, n_jobs=1, n_neighbors=5, p=1,\n",
    "#           weights='uniform'))])\n",
    "#\tAccuracy: 0.88013\tPrecision: 0.64470\tRecall: 0.22500\tF1: 0.33358\tF2: 0.25868\n",
    "#\tTotal predictions: 15000\tTrue positives:  450\tFalse positives:  248\tFalse negatives: 1550\tTrue negatives: 12752\n",
    "'''\n",
    "\n",
    "'''\n",
    "#Ensemble AdaBoost\n",
    "ensemble = ensemble.AdaBoostClassifier()\n",
    "parameters = {'ensemble__n_estimators': [10, 20, 40]}\n",
    "Min_Max_scaler = MinMaxScaler()\n",
    "#features = Min_Max_scaler.fit_transform(features)\n",
    "pipeline = Pipeline(steps=[('scaler', Min_Max_scaler), ('pca',PCA(n_components = 2)), ('ensemble', ensemble)])\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "#Results - Outliers = TOTAL, 'THE TRAVEL AGENCY IN THE PARK'\n",
    "#Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, n_components=2, whiten=False)), ('ensemble', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "#          learning_rate=1.0, n_estimators=10, random_state=None))])\n",
    "#\tAccuracy: 0.83500\tPrecision: 0.26083\tRecall: 0.12950\tF1: 0.17307\tF2: 0.14400\n",
    "#\tTotal predictions: 15000\tTrue positives:  259\tFalse positives:  734\tFalse negatives: 1741\tTrue negatives: 12266\n",
    "\n",
    "#Results - Outliers = All\n",
    "#Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, n_components=2, whiten=False)), ('ensemble', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "#          learning_rate=1.0, n_estimators=10, random_state=None))])\n",
    "#\tAccuracy: 0.83064\tPrecision: 0.33363\tRecall: 0.18600\tF1: 0.23884\tF2: 0.20406\n",
    "#\tTotal predictions: 14000\tTrue positives:  372\tFalse positives:  743\tFalse negatives: 1628\tTrue negatives: 11257\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "#Tree Classifier\n",
    "tree = DecisionTreeClassifier()\n",
    "parameters = {'tree__criterion': ('gini','entropy'),\n",
    "              'tree__splitter':('best','random'),\n",
    "              'tree__min_samples_split':[1, 2, 10, 20],\n",
    "                'tree__max_depth':[10,15,20,25],\n",
    "                'tree__max_leaf_nodes':[10,30,50,70]}\n",
    "\n",
    "\n",
    "# use scaling in GridSearchCV\n",
    "Min_Max_scaler = MinMaxScaler()\n",
    "#features = Min_Max_scaler.fit_transform(features)\n",
    "pipeline = Pipeline(steps=[('scaler', Min_Max_scaler), ('pca',PCA(n_components = 2)), ('tree', tree)])\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "#Results - Outliers = TOTAL, 'THE TRAVEL AGENCY IN THE PARK'\n",
    "#Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, n_components=2, whiten=False)), ('tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
    "#            max_features=None, max_leaf_nodes=70, min_samples_leaf=1,\n",
    "#            min_samples_split=1, min_weight_fraction_leaf=0.0,\n",
    "#            presort=False, random_state=None, splitter='random'))])\n",
    "#\tAccuracy: 0.81140\tPrecision: 0.23849\tRecall: 0.18900\tF1: 0.21088\tF2: 0.19718\n",
    "#\tTotal predictions: 15000\tTrue positives:  378\tFalse positives: 1207\tFalse negatives: 1622\tTrue negatives: 11793\n",
    "\n",
    "#Results - Outliers = All\n",
    "#Pipeline(steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('pca', PCA(copy=True, n_components=2, whiten=False)), ('tree', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=20,\n",
    "#            max_features=None, max_leaf_nodes=70, min_samples_leaf=1,\n",
    "#            min_samples_split=1, min_weight_fraction_leaf=0.0,\n",
    "#            presort=False, random_state=None, splitter='best'))])\n",
    "#\tAccuracy: 0.80171\tPrecision: 0.29834\tRecall: 0.28700\tF1: 0.29256\tF2: 0.28920\n",
    "#\tTotal predictions: 14000\tTrue positives:  574\tFalse positives: 1350\tFalse negatives: 1426\tTrue negatives: 10650\n",
    "'''\n",
    "\n",
    "#GridSearch\n",
    "gs = GridSearchCV(pipeline, parameters, cv=cv, scoring='f1')\n",
    "\n",
    "gs.fit(features, labels)\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
    "### using our testing script.\n",
    "### Because of the small size of the dataset, the script uses stratified\n",
    "### shuffle split cross validation. For more info: \n",
    "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
    "\n",
    "test_classifier(clf, my_dataset, features_list)\n",
    "\n",
    "### Dump your classifier, dataset, and features_list so \n",
    "### anyone can run/check your results.\n",
    "\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
